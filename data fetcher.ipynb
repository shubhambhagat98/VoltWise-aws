{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorators\n",
    "def error_log(function_name):\n",
    "    def inner_decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                print(f\"Function {function_name} encountered an error: {e}\")\n",
    "                \n",
    "        return wrapper\n",
    "    return inner_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @error_log('fetch_data')\n",
    "def fetch_data(url):\n",
    "\n",
    "    # call API\n",
    "    r = requests.get(url)\n",
    "    op = r.json()\n",
    "    \n",
    "    # json to data frame\n",
    "    df = pd.json_normalize(op['response']['data'])\n",
    "    df = df.pivot(columns=\"type-name\", values='value', index = ['period', 'respondent'] )\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    # organize data as needed\n",
    "    df.drop(columns=['Day-ahead demand forecast','Total interchange'], inplace=True)\n",
    "    df[['Date', 'Hour']] = df['period'].str.split('T',expand=True)\n",
    "    df = df.drop('period', axis = 1)\n",
    "    df.rename(columns={'respondent':'region'}, inplace=True)\n",
    "    df = df[['Date','Hour','region','Demand','Net generation']]\n",
    "    \n",
    "    # segregate data based on regions\n",
    "    final_dict = segregate_to_region(df)\n",
    "\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @error_log('segregate_to_region')\n",
    "def segregate_to_region(df):\n",
    "    data = {}\n",
    "    for r in regions:\n",
    "        data[r] = df[df['region']==r].reset_index().drop(columns=['index'])\n",
    "        if len(data[r])<96:\n",
    "            temp = data_correction(r,data[r])\n",
    "            temp.reset_index(inplace=True)\n",
    "            temp.drop(columns=['index'],inplace=True)\n",
    "            data[r] = temp\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @error_log('data_correction')\n",
    "def data_correction(r,df):\n",
    "    hour = ['{:02d}'.format(i) for i in range(24)]\n",
    "    uq_date = df['Date'].unique().tolist()\n",
    "    dfs=[]\n",
    "    for dt in uq_date:\n",
    "        uq_hour = df[df['Date']==dt]['Hour'].unique().tolist()\n",
    "        missing_hr = [x for x in hour if x not in uq_hour]\n",
    "        if len(missing_hr)!=0:\n",
    "            new_df=generate_data(df[(df['Date']==dt)],missing_hr,r,dt)\n",
    "#             print(r,dt,missing_hr,len(new_df))\n",
    "            dfs.append(new_df)\n",
    "        else:\n",
    "            dfs.append(df[(df['Date']==dt)])\n",
    "    print(uq_date)\n",
    "    dfs = pd.concat(dfs)\n",
    "#     print(len(dfs))\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @error_log('generate_data')\n",
    "def generate_data(df,missing_hr,r,dt):\n",
    "    \n",
    "    demand_median = df['Demand'].median()\n",
    "    net_gen_median = df['Net generation'].median()\n",
    "    \n",
    "    new_data=[]\n",
    "    for hr in missing_hr:\n",
    "        new_data.append((dt,hr,r,demand_median,net_gen_median))\n",
    "        \n",
    "    df_missing = pd.DataFrame(new_data,columns=['Date', 'Hour', 'region','Demand','Net generation'])\n",
    "    df_new = pd.concat([df,df_missing])\n",
    "    df_new = df_new.sort_values(['Date','Hour'])\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @error_log('get_new_dates')\n",
    "def get_new_dates(start_date,end_date):\n",
    "    start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "    st =  end_date + datetime.timedelta(days=1)\n",
    "    start_date = st.strftime('%Y-%m-%d')\n",
    "    end_date = (st + datetime.timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    return start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date =  \"2015-07-01\"\n",
    "end_date = \"2015-07-04\"\n",
    "regions = ['CAL', 'CAR', 'CENT', 'FLA', 'MIDA', 'MIDW', 'NE', 'NY', 'SE', 'SW', 'TEN', 'TEX']\n",
    "region_data_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while end_date<='2023-03-15':\n",
    "    \n",
    "    url= f\"https://api.eia.gov/v2/electricity/rto/region-data/data/?\\\n",
    "frequency=hourly&data[0]=value&facets[respondent][]=CAL\\\n",
    "&facets[respondent][]=CAR&facets[respondent][]=CENT&facets[respondent][]=FLA&facets[respondent][]=MIDA\\\n",
    "&facets[respondent][]=MIDW&facets[respondent][]=NE&facets[respondent][]=NY&facets[respondent][]=SE&\\\n",
    "facets[respondent][]=SW&facets[respondent][]=TEX&\\\n",
    "start={start_date}T00&end={end_date}T23\\\n",
    "&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000\\\n",
    "&api_key=2Ztw7IK10RqAv0oag9T2o2FOV8YZgRpapfTEvhwH\"\n",
    "    print(f'Now fetching data from {start_date} to {end_date}')\n",
    "    temp=fetch_data(url)\n",
    "    ct=0\n",
    "    for k in temp.keys():\n",
    "        if k in region_data_dict.keys():\n",
    "            region_data_dict[k].append(temp[k])\n",
    "            ct+=len(temp[k])\n",
    "        else:\n",
    "            region_data_dict[k]=[temp[k]]\n",
    "            ct+=len(temp[k])\n",
    "\n",
    "    print(f'Got demand data from date {start_date} to {end_date} and its count is {ct}')\n",
    "    \n",
    "    start_date,end_date = get_new_dates(start_date,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_data_dict_copy = dict(region_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in region_data_dict_copy.keys():\n",
    "    region_data_dict_copy[k]=pd.concat(region_data_dict_copy[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in region_data_dict_copy.keys():\n",
    "    region_data_dict_copy[k].to_csv(f'{k}--2015-07-01--2023-03-15.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
