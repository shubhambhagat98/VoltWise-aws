{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from functools import wraps\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorators\n",
    "def error_log(function_name):\n",
    "    def inner_decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                print(f\"Function {function_name} encountered an error: {e}\")\n",
    "                \n",
    "        return wrapper\n",
    "    return inner_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@error_log('fetch_data')\n",
    "def fetch_data(url):\n",
    "\n",
    "    # call API\n",
    "    r = requests.get(url)\n",
    "    op = r.json()\n",
    "    \n",
    "    # json to data frame\n",
    "    df = pd.json_normalize(op['response']['data'])\n",
    "\n",
    "    df = df.pivot(columns=\"type-name\", values='value', index = ['period', 'respondent'] )\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    # organize data as needed\n",
    "    df.drop(columns=['Day-ahead demand forecast','Total interchange'], inplace=True)\n",
    "    df[['Date', 'Hour']] = df['period'].str.split('T',expand=True)\n",
    "    df = df.drop('period', axis = 1)\n",
    "    df.rename(columns={'respondent':'region'}, inplace=True)\n",
    "    df = df[['Date','Hour','region','Demand','Net generation']]\n",
    "    # segregate data based on regions\n",
    "\n",
    "    final_dict = segregate_to_region(df)\n",
    "\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@error_log('segregate_to_region')\n",
    "def segregate_to_region(df):\n",
    "    data = {}\n",
    "    for r in regions:\n",
    "        data[r] = df[df['region']==r].reset_index().drop(columns=['index'])\n",
    "        \n",
    "        if len(data[r])<96:\n",
    "            temp = data_correction(r,data[r])\n",
    "            temp.reset_index(inplace=True)\n",
    "            temp.drop(columns=['index'],inplace=True)\n",
    "            data[r] = temp\n",
    "        print(f'Got demand data for region {r} and its count is {len(data[r])}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @error_log('data_correction')\n",
    "def data_correction(r,df):\n",
    "    hour = ['{:02d}'.format(i) for i in range(24)]\n",
    "    uq_date = df['Date'].unique().tolist()\n",
    "    dfs=[]\n",
    "    for dt in uq_date:\n",
    "        uq_hour = df[df['Date']==dt]['Hour'].unique().tolist()\n",
    "        missing_hr = [x for x in hour if x not in uq_hour]\n",
    "        if len(missing_hr)!=0:\n",
    "            new_df=generate_data(df[(df['Date']==dt)],missing_hr,r,dt)\n",
    "#             print(r,dt,missing_hr,len(new_df))\n",
    "            dfs.append(new_df)\n",
    "        else:\n",
    "            dfs.append(df[(df['Date']==dt)])\n",
    "    print(uq_date)\n",
    "    dfs = pd.concat(dfs)\n",
    "#     print(len(dfs))\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@error_log('generate_data')\n",
    "def generate_data(df,missing_hr,r,dt):\n",
    "    \n",
    "    demand_median = df['Demand'].median()\n",
    "    net_gen_median = df['Net generation'].median()\n",
    "    \n",
    "    new_data=[]\n",
    "    for hr in missing_hr:\n",
    "        new_data.append((dt,hr,r,demand_median,net_gen_median))\n",
    "        \n",
    "    df_missing = pd.DataFrame(new_data,columns=['Date', 'Hour', 'region','Demand','Net generation'])\n",
    "    df_new = pd.concat([df,df_missing])\n",
    "    df_new = df_new.sort_values(['Date','Hour'])\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "@error_log('get_new_dates')\n",
    "def get_new_dates(end_date):\n",
    "    end_date = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "    start_date =  (end_date - datetime.timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "  \n",
    "    return start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "@error_log('get_new_dates')\n",
    "def update_raw_data():\n",
    "    for k in regions:\n",
    "        historic_region_data[k]=pd.read_parquet(f'{k}')\n",
    "\n",
    "        new_data[k]['new_hash_time'] = new_data[k]['Date']+new_data[k]['Hour']\n",
    "        historic_region_data[k]['new_hash_time'] = historic_region_data[k]['Date']+historic_region_data[k]['Hour'].astype(str)\n",
    "\n",
    "        # Set the 'id' column as the index of both DataFrames\n",
    "        new_data[k].set_index('new_hash_time', inplace=True)\n",
    "        historic_region_data[k].set_index('new_hash_time', inplace=True)\n",
    "\n",
    "        # Update rows in df that have matching indexes in new_data\n",
    "        historic_region_data[k].update(new_data[k])\n",
    "\n",
    "        # Append rows to df that have non-matching indexes in new_data\n",
    "        historic_region_data[k] = pd.concat([historic_region_data[k], new_data[k].loc[~new_data[k].index.isin(historic_region_data[k].index)]])\n",
    "\n",
    "        # Reset the index of the resulting DataFrame\n",
    "        historic_region_data[k].reset_index(inplace=True)\n",
    "\n",
    "        historic_region_data[k].drop(columns=['new_hash_time'],inplace=True)\n",
    "        \n",
    "        historic_region_data[k].to_parquet(f'{k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "end_date = \"2023-03-21\"\n",
    "start_date = get_new_dates(end_date)\n",
    "regions = ['CAL', 'CAR', 'CENT', 'FLA', 'MIDA', 'MIDW', 'NE', 'NY', 'SE', 'SW', 'TEN', 'TEX']\n",
    "historic_region_data={}\n",
    "historic_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now fetching data from 2023-03-18 to 2023-03-21\n",
      "Got demand data for region CAL and its count is 96\n",
      "Got demand data for region CAR and its count is 96\n",
      "Got demand data for region CENT and its count is 96\n",
      "Got demand data for region FLA and its count is 96\n",
      "Got demand data for region MIDA and its count is 96\n",
      "Got demand data for region MIDW and its count is 96\n",
      "Got demand data for region NE and its count is 96\n",
      "Got demand data for region NY and its count is 96\n",
      "Got demand data for region SE and its count is 96\n",
      "Got demand data for region SW and its count is 96\n",
      "Got demand data for region TEN and its count is 96\n",
      "Got demand data for region TEX and its count is 96\n",
      "Got demand data from date 2023-03-18 to 2023-03-21\n",
      "Updated new data from date 2023-03-18 to 2023-03-21\n"
     ]
    }
   ],
   "source": [
    "url= f\"https://api.eia.gov/v2/electricity/rto/region-data/data/?\\\n",
    "frequency=hourly&data[0]=value&facets[respondent][]=CAL\\\n",
    "&facets[respondent][]=CAR&facets[respondent][]=CENT&facets[respondent][]=FLA&facets[respondent][]=MIDA\\\n",
    "&facets[respondent][]=MIDW&facets[respondent][]=NE&facets[respondent][]=NY&facets[respondent][]=SE&\\\n",
    "facets[respondent][]=SW&facets[respondent][]=TEN&facets[respondent][]=TEX&\\\n",
    "start={start_date}T00&end={end_date}T23\\\n",
    "&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000\\\n",
    "&api_key=2Ztw7IK10RqAv0oag9T2o2FOV8YZgRpapfTEvhwH\"\n",
    "\n",
    "print(f'Now fetching data from {start_date} to {end_date}')\n",
    "new_data=fetch_data(url)\n",
    "\n",
    "print(f'Got demand data from date {start_date} to {end_date}')\n",
    "\n",
    "update_raw_data()\n",
    "\n",
    "print(f'Updated new data from date {start_date} to {end_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
